---
layout: "post"
language: "de"
title: "DFKI warnt vor trügerischer Erklärbarkeit in KI-Systemen"
aigenerated: true
---

### DFKI warnt vor trügerischer Erklärbarkeit in KI-Systemen

Das Deutsche Forschungszentrum für Künstliche Intelligenz (DFKI) hat auf der diesjährigen Konferenz ICML 2025 eine Studie vorgestellt, die auf die Risiken sogenannter "erklärbarer KI" hinweist. Die Forscher betonen, dass die Erklärbarkeit von KI-Systemen oft eine Illusion sein kann, insbesondere wenn automatisierte Methoden wie AutoML (Automated Machine Learning) verwendet werden. David Antony Selby, Wissenschaftler im Bereich Data Science am DFKI, erklärte: "Die Erklärbarkeit eines Modells kann zur Illusion werden, besonders wenn viele plausible, aber widersprüchliche Modelle zur Auswahl stehen." Diese Problematik, auch als "X-Hacking" bezeichnet, zeigt, wie leicht Erklärungen manipuliert oder missverstanden werden können, was die Vertrauenswürdigkeit von KI-Systemen gefährdet.

<!--more-->

Die Studie hebt hervor, dass die automatisierte Auswahl von Modellen durch AutoML zwar die Entwicklung von KI-Systemen beschleunigt, jedoch auch die Gefahr birgt, dass die erzeugten Erklärungen nicht die tatsächlichen Entscheidungsprozesse widerspiegeln. Dies könnte dazu führen, dass Anwender und Entscheidungsträger falsche Schlüsse ziehen. Das DFKI plädiert daher für eine reflektierte Nutzung solcher Technologien und fordert, dass die Grenzen der Erklärbarkeit klar kommuniziert werden. Die Forschung ist Teil des strategischen Schwerpunkts "Trustworthy AI", mit dem das DFKI die gesellschaftliche Akzeptanz und Transparenz von KI-Systemen fördern möchte.

### Quellen
- [ICML 2025: DFKI warnt vor trügerischer Erklärbarkeit in KI-Systemen](https://www.dfki.de/web/news/icml-2025-truegerische-erklaerbarkeit-in-ki-systemen)  
- [MT-Dialog: Risiko bei erklärbarer künstlicher Intelligenz](https://www.mtdialog.de/news-fachbeitraege/themen/artikel/risiko-bei-erklaerbarer-kuenstlicher-intelligenz)
